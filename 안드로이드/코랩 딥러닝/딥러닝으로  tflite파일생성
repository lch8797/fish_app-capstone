import tensorflow as tf
batch_size = 128 # 가중치를 변경하기 전에 처리하는 샘플의 개수
num_classes = 10 # 출력 클래스의 개수
epochs = 20 # 에포크의 개수
# 데이터를 학습 데이터와 테스트 데이터 나누어 가져옴
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
# 입력 이미지를 2차원에서 1차원 벡터로 변경
x_train = x_train.reshape(60000, 784)
x_test = x_test.reshape(10000, 784)
# 입력 이미지의 픽셀 값이 0.0에서 1.0 사이의 값으로 변환
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
# 클래스의 개수에 따라서 하나의 출력 픽셀만이 1이 되게 함 : 원핫 인코딩# 예, 0을 1 0 0 0 0 0 0 0 0 0, 3을 0 0 0 1 0 0 0 0 0 0
y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_test = tf.keras.utils.to_categorical(y_test, num_classes)
# 신경망의 모델을 구축
model = tf.keras.models.Sequential()

#은닉층 추가 ------------ 성능비교
model.add(tf.keras.layers.Dense(512, activation='relu',
input_shape=(784,)))
model.add(tf.keras.layers.Dense(312, activation='relu',
input_shape=(512,)))
#model.add(tf.keras.layers.Dense(212, activation='relu',
#input_shape=(312,)))
model.add(tf.keras.layers.Dense(num_classes, activation='relu'))
model.summary()

#옵티마이저 Adam 설정후--------- 성능비교---------------------------------------
adam = tf.keras.optimizers.SGD(lr=0.1)

#sgd = tf.keras.optimizers.SGD(lr=0.1)

# 손실 함수를 제곱 오차 함수로 설정하고 학습 알고리즘은 SGD 방식으로
model.compile(loss='mean_squared_error',

optimizer=adam,
#optimizer=sgd,
metrics=['accuracy'])
# 학습 수행
history = model.fit(x_train, y_train,
batch_size=batch_size,
epochs=epochs)
# 학습 결과 평가
score = model.evaluate(x_test, y_test, verbose=0)
print('테스트 손실값:', score[0])
print('테스트 정확도:', score[1])
